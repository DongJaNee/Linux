# Slurm í´ëŸ¬ìŠ¤í„° êµ¬ì¶• ê°€ì´ë“œ (RHEL 9.5 ê¸°ì¤€)

## ğŸ“Œ í™˜ê²½ êµ¬ì„±
* Head Node IP: `192.168.0.44`, hostname: `headnode`
* Compute Node IP: `192.168.0.37`, hostname: `computenode`

## ğŸ”¹ Head Node ì‘ì—…

### 1. ì‹œìŠ¤í…œ ì¤€ë¹„
```bash
sudo subscription-manager repos --enable codeready-builder-for-rhel-9-$(uname -m)-rpms (epel download)
sudo dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm (epel download)

sudo dnf install -y epel-release
sudo dnf install -y munge munge-libs munge-devel slurm slurm-slurmd slurm-slurmctld
```

### 2. í˜¸ìŠ¤íŠ¸ëª… ë° hosts íŒŒì¼ ì„¤ì •
```bash
sudo hostnamectl set-hostname headnode
```

`/etc/hosts` íŒŒì¼ì— ë‹¤ìŒ ë‚´ìš© ì¶”ê°€:
```
192.168.0.44 headnode
192.168.0.37 computenode
```

### 3. SSH ì„¤ì •
```bash
sudo systemctl enable sshd --now


sudo nano /etc/ssh/sshd_config 
PermitRootLogin yes (# ì œê±°)
PasswordAuthentication yes (# ì œê±°)

```

### 4. Munge ì„¤ì •
```bash
sudo /usr/sbin/create-munge-key
sudo chown munge:munge /etc/munge/munge.key
sudo chmod 400 /etc/munge/munge.key
sudo systemctl enable --now munge
```

### 5. Slurm ì„¤ì •

`slurm.conf` ìƒì„±
```bash
sudo vi /etc/slurm/slurm.conf
```

ì˜ˆì‹œ:
```
ClusterName=cluster
ControlMachine=headnode
SlurmUser=slurm
SlurmctldPort=6817
SlurmdPort=6818
AuthType=auth/munge
StateSaveLocation=/var/spool/slurmctld
SlurmdSpoolDir=/var/spool/slurmd
SwitchType=switch/none
MpiDefault=none
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid
ProctrackType=proctrack/pgid
ReturnToService=2
SlurmctldTimeout=120
SlurmdTimeout=300
SchedulerType=sched/backfill
SelectType=select/cons_res
SelectTypeParameters=CR_Core
NodeName=computenode NodeAddr=192.168.0.37 CPUs=2 State=UNKNOWN
PartitionName=debug Nodes=computenode Default=YES MaxTime=INFINITE State=UP
```

Slurm ì‚¬ìš©ì ë° ê·¸ë£¹ ìƒì„±
```bash
sudo useradd -r -c "Slurm user" -s /sbin/nologin slurm
sudo chown slurm:slurm /var/log/slurmctld.log
```

Slurm ë””ë ‰í† ë¦¬ ì¤€ë¹„
```bash
sudo mkdir -p /var/spool/slurmctld
sudo chown slurm:slurm /var/spool/slurmctld
sudo touch /var/log/slurmctld.log
sudo chown slurm:slurm /var/log/slurmctld.log
```
### 7. Slurmctld Daemon ì„¤ì • 
```bash
sudo vi /etc/systemd/system/slurmctld.service
```
```bash
[Unit]
Description=Slurm controller daemon
After=network.target munge.service

[Service]
Type=simple
User=slurm
ExecStart=/usr/sbin/slurmctld -D
Restart=always

[Install]
WantedBy=multi-user.target
```

### 8. Slurmd Daemon ì„¤ì • 
```bash
sudo vi /etc/systemd/system/slurmd.service
```
```bash
[Unit]
Description=Slurm node daemon
After=network.target munge.service

[Service]
Type=simple
User=root
ExecStart=/usr/sbin/slurmd -D
Restart=always

[Install]
WantedBy=multi-user.target
```
```ì ìš© ë° ì‹¤í–‰
sudo systemctl daemon-reload
sudo systemctl enable --now slurmctld   # Head nodeë§Œ
sudo systemctl enable --now slurmd      # ëª¨ë“  ë…¸ë“œì—ì„œ
```
```ìƒíƒœ í™•ì¸
systemctl status slurmctld
systemctl status slurmd
```

### 9. Slurm ì„œë¹„ìŠ¤ ì‹¤í–‰
```bash
sudo systemctl enable --now slurmctld
```

## ğŸ”¹ Compute Node ì‘ì—…

### 1. ì‹œìŠ¤í…œ ì¤€ë¹„
```bash
sudo subscription-manager repos --enable codeready-builder-for-rhel-9-$(uname -m)-rpms (epel download)
sudo dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm (epel download)

sudo dnf install -y epel-release
sudo dnf install -y munge munge-libs munge-devel slurm slurm-slurmd
```

### 2. í˜¸ìŠ¤íŠ¸ëª… ë° hosts íŒŒì¼ ì„¤ì •
```bash
sudo hostnamectl set-hostname computenode
```

`/etc/hosts` íŒŒì¼ì— ë‹¤ìŒ ë‚´ìš© ì¶”ê°€:
```
192.168.0.44 headnode
192.168.0.37 computenode
```

### 3. SSH ì„¤ì •
```bash
sudo systemctl enable sshd --now

sudo firewall-cmd --add-service=ssh --permanent (ë°©í™”ë²½ ì—´ê¸°)
sudo firewall-cmd --reload (ë°©í™”ë²½ ì—´ê¸°)
```

```bash
sudo nano /etc/ssh/sshd_config 
PermitRootLogin yes (# ì œê±°)
PasswordAuthentication yes (# ì œê±°)

sudo systemctl restart sshd (sshd ë°ëª¬ ì¬ì‹œì‘)

### 4. Munge í‚¤ ë³µì‚¬ ë° ì„¤ì •
```bash
# Head Nodeì—ì„œ ì‹¤í–‰:
scp /etc/munge/munge.key root@192.168.0.37:/etc/munge/munge.key

# Compute Nodeì—ì„œ ì‹¤í–‰:
sudo chown munge:munge /etc/munge/munge.key
sudo chmod 400 /etc/munge/munge.key
sudo systemctl enable --now munge
```

### 5. slurm.conf ë³µì‚¬
```bash
# Head Nodeì—ì„œ ì‹¤í–‰:
scp /etc/slurm/slurm.conf root@192.168.0.37:/etc/slurm/slurm.conf
```

### 6. Slurm ë””ë ‰í† ë¦¬ ì¤€ë¹„
```bash
sudo groupadd slurm (slurm ê·¸ë£¹ìƒì„±)
sudo useradd -g slurm slurm (slurm í•´ë‹¹ê·¸ë£¹ì— ì¶”ê°€ ìƒì„±)  



sudo mkdir -p /var/spool/slurmd
sudo chown slurm:slurm /var/spool/slurmd
sudo touch /var/log/slurmd.log
sudo chown slurm:slurm /var/log/slurmd.log
```

### 7. (í•„ìš” ì‹œ) slurmd ì„œë¹„ìŠ¤ ìˆ˜ë™ ìƒì„±
ê²½ë¡œ í™•ì¸ í›„ ì•„ë˜ì²˜ëŸ¼ ì§ì ‘ ìƒì„±
```bash
sudo vi /etc/systemd/system/slurmd.service
```

```
[Unit]
Description=Slurm node daemon
After=network.target munge.service

[Service]
Type=simple
ExecStart=/usr/sbin/slurmd -D
User=root

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl daemon-reexec
```

### 8. slurmd ì„œë¹„ìŠ¤ ì‹œì‘
```bash
sudo systemctl enable --now slurmd
```

## ğŸ” ìƒíƒœ í™•ì¸ ë° í…ŒìŠ¤íŠ¸

Head Nodeì—ì„œ í™•ì¸
```bash
sinfo
scontrol show nodes
```

Slurm í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (test_job.sh)
```bash
#!/bin/bash
#SBATCH --job-name=gpu_test
#SBATCH --output=/home/slurm/gpu_result.txt
#SBATCH --error=/home/slurm/gpu_error.txt
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=1G
#SBATCH --time=00:02:00
#SBATCH --partition=debug
#SBATCH --gres=gpu:1  # GPU 1ê°œ ìš”ì²­ (Slurmì— GRES ì„¤ì •ì´ ìˆì–´ì•¼ í•¨)

echo "=== GPU í…ŒìŠ¤íŠ¸ ì‹œì‘ ==="
hostname
date
echo ""
echo "=== GPU ì •ë³´ ==="
nvidia-smi

```

```bash
sbatch test_job.sh
cat result.txt
```

**â€»Cat ëª…ë ¹ì–´ê°€ ì‹¤í–‰ì´ ì•ˆë˜ê±°ë‚˜ hostname ì´ ë‹¤ë¥´ë©´ hostnameì„ ë§ì¶”ê³  sudo rebootë¡œ ì„œë²„ rebootì‹œí‚¤ê³  mungeì™€ slurm ì¬ì‹¤í–‰**
## âœ… ì°¸ê³ 
* `scontrol ping` ìœ¼ë¡œ ë…¸ë“œ ì—°ê²° ìƒíƒœ í™•ì¸ ê°€ëŠ¥
* ëª¨ë“  ì„¤ì • í›„ ë°©í™”ë²½, SELinuxê°€ ì°¨ë‹¨í•˜ê³  ìˆëŠ”ì§€ ì—¬ë¶€ í™•ì¸ í•„
